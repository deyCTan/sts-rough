# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE
import pandas as pd
import re

# Function to clean text
def clean_text(text):
    """
    Cleans a single text entry by:
    1. Replacing 'N/A' and NaN-like values with an empty string.
    2. Removing repeated words, technical text, code, or symbols (keeping a single instance).
    3. Handling repeated words separated by a hyphen (e.g., "comp - comp" → "comp").
    4. Trimming extra spaces.
    Args:
        text (str): The text to clean.
    Returns:
        str: The cleaned text.
    """
    if not isinstance(text, str) or text.strip().lower() in ["nan", "none"]:
        return ""  # Replace non-string, NaN, or "nan"/"none" values with an empty string

    # Replace 'N/A' with an empty string
    text = text.replace("N/A", "").strip()

    # Handle repeated words separated by a hyphen (e.g., "comp - comp" → "comp")
    text = re.sub(r'\b(\w+)\s*-\s*\1\b', r'\1', text, flags=re.IGNORECASE)

    # Remove repeated words or symbols (e.g., "error error" → "error")
    text = re.sub(r'\b(\w+)(\s+\1\b)+', r'\1', text, flags=re.IGNORECASE)

    # Remove repeating special characters or symbols (e.g., ---- or ####)
    text = re.sub(r'([^\w\s])\1+', r'\1', text)

    # Trim leading/trailing spaces and normalize multiple spaces to a single space
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# Read recipe inputs
sts_cmb_trns = dataiku.Dataset("sts_cmb_trns")
sts_cmb_trns_df = sts_cmb_trns.get_dataframe()

# Ensure relevant columns are treated as strings and handle NaN values
columns_to_process = ["solution_final_translated", "problem_cause_text_translated", "observation_final_translated"]

for column in columns_to_process:
    if column in sts_cmb_trns_df.columns:
        # Convert all values to strings and handle NaN
        sts_cmb_trns_df[column] = sts_cmb_trns_df[column].astype(str).replace(["nan", "None"], "", regex=True)
    else:
        print(f"Warning: Column '{column}' not found in DataFrame.")

# Combine `solution_final_translated` and `problem_cause_text_translated`
sts_cmb_trns_df["solution_problem_combined"] = sts_cmb_trns_df.apply(
    lambda row: clean_text(row["problem_cause_text_translated"])
    + (" - " if clean_text(row["problem_cause_text_translated"]) and clean_text(row["solution_final_translated"]) else "")
    + clean_text(row["solution_final_translated"]),
    axis=1
)

# Clean the `observation_final_translated` column
if "observation_final_translated" in sts_cmb_trns_df.columns:
    sts_cmb_trns_df["observation_final_translated"] = sts_cmb_trns_df["observation_final_translated"].apply(clean_text)
else:
    print("Warning: Column 'observation_final_translated' not found in DataFrame.")

# Rename columns for consistency
sts_cmb_trns_df.rename(
    columns={
        "solution_problem_combined": "sol_final_trns",
        "observation_final_translated": "obs_final_trns"
    },
    inplace=True
)

# Write back to Dataiku
embedding_columns = ["sol_final_trns", "obs_final_trns"]
sts_cmb_trns_cleaned = dataiku.Dataset("sts_cmb_trns_cln")
sts_cmb_trns_cleaned.write_with_schema(sts_cmb_trns_df)
